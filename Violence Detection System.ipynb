{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: YOLO Object Detection\n",
    "def detect_objects(frame, yolo_model, classes):\n",
    "    results = yolo_model(frame)\n",
    "    for result in results:\n",
    "        bboxes = result.boxes\n",
    "        b=bboxes.xyxy.cpu().numpy()\n",
    "        boxes=b.astype(int)\n",
    "        cls=bboxes.cls\n",
    "        class_indices=cls.cpu().numpy()\n",
    "        labels = [result.names[i] for i in class_indices]\n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Image Classification using CNN\n",
    "def classify_frame(frame, model):\n",
    "    # Preprocess the frame (resize, normalize, etc.)\n",
    "    frame = cv2.resize(frame, (224, 224))  # Assuming input size of the CNN model\n",
    "    frame = frame / 255.0  # Normalize pixel values to [0, 1]\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    # Perform violence classification using the CNN model\n",
    "    prediction = model.predict(frame)\n",
    "    if prediction[0][0] > 0.5:\n",
    "        return \"Violent\"\n",
    "    else:\n",
    "        return \"Non-Violent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "    \n",
    "def save_processed_frame(frame, save_path):\n",
    "    cv2.imwrite(save_path, frame)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    # Load YOLO model\n",
    "    yolo_model = YOLO('yolov8n.pt')  # You can specify yolov5s, yolov5m, yolov5l, or yolov5x\n",
    "    # Load class labels (coco.names)\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # Load CNN model for violence classification\n",
    "    cnn_model = load_model(\"D:/lab_last/model.h5\")\n",
    "    \n",
    "    # Open the webcam\n",
    "      # Use index 0 for the primary webcam\n",
    "    # cam = Picamera2()\n",
    "    # cam.preview_configuration.main.size = (640, 360)\n",
    "    # cam.preview_configuration.main.format = \"RGB888\"\n",
    "    # cam.preview_configuration.controls.FrameRate = 30\n",
    "    # cam.preview_configuration.align()\n",
    "    # cam.configure(\"preview\")\n",
    "    # cam.start()\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = video_capture.read()\n",
    "        # frame = cam.capture_array()\n",
    "        if not ret:\n",
    "            break  # Break the loop if there are no more frames\n",
    "        \n",
    "        # Step 1: YOLO Object Detection\n",
    "        detected_boxes, detected_labels = detect_objects(frame, yolo_model, classes)\n",
    "        \n",
    "        # Check if YOLO detected humans, guns, or knives\n",
    "        if any(label in ['person', 'gun', 'knife'] for label in detected_labels):\n",
    "            # Step 2: Image Classification using CNN\n",
    "            for bbox, label in zip(detected_boxes, detected_labels):\n",
    "                x, y, w, h = bbox\n",
    "                object_frame = frame[y:y+h, x:x+w]\n",
    "                predicted_class = classify_frame(object_frame, cnn_model)\n",
    "                # Perform further processing based on the predicted class\n",
    "                if predicted_class == 'Violent':\n",
    "                    # Draw bounding box and label for violent object\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, 'Violent', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    # Add your warning logic here\n",
    "                    print(\"Warning: Violent Object Detected!\")\n",
    "                else:\n",
    "                    # Draw bounding box and label for non-violent object\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'Non-Violent', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    # Add your non-violent object logic here\n",
    "        \n",
    "        # Display the processed frame\n",
    "        cv2.imshow('Violence Detection', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and close all windows\n",
    "    # cam.stop\n",
    "    # # vid.release()\n",
    "    # cv.destroyAllWindows()\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the main function to process video from the webcam\n",
    "process_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    # Load YOLO model\n",
    "    yolo_model = YOLO('yolov8n.pt')  # You can specify yolov5s, yolov5m, yolov5l, or yolov5x\n",
    "    # Load class labels (coco.names)\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # Load CNN model for violence classification\n",
    "    cnn_model = load_model(\"D:/lab_last/model.h5\")\n",
    "    \n",
    "    # Open the webcam\n",
    "    video_capture = cv2.VideoCapture(video_path)  # Use index 0 for the primary webcam\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    while True:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break  # Break the loop if there are no more frames\n",
    "        \n",
    "        # Step 1: YOLO Object Detection\n",
    "        detected_boxes, detected_labels = detect_objects(frame, yolo_model, classes)\n",
    "        \n",
    "        # Check if YOLO detected humans, guns, or knives\n",
    "        if any(label in ['person', 'gun', 'knife'] for label in detected_labels):\n",
    "            # Step 2: Image Classification using CNN\n",
    "            for bbox, label in zip(detected_boxes, detected_labels):\n",
    "                x, y, w, h = bbox\n",
    "                object_frame = frame[y:y+h, x:x+w]\n",
    "                predicted_class = classify_frame(object_frame, cnn_model)\n",
    "                true_labels.append(label)\n",
    "                predicted_labels.append(predicted_class)\n",
    "                # Perform further processing based on the predicted class\n",
    "                if predicted_class == 'Violent':\n",
    "                    # Draw bounding box and label for violent object\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, 'Violent', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    # Add your warning logic here\n",
    "                    print(\"Warning: Violent Object Detected!\")\n",
    "                else:\n",
    "                    # Draw bounding box and label for non-violent object\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'Non-Violent', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    # Add your non-violent object logic here\n",
    "        \n",
    "        # Display the processed frame\n",
    "        cv2.imshow('Violence Detection', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and close all windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the main function to process video from the webcam\n",
    "process_video(\"path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
